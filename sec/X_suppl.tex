\clearpage
\setcounter{page}{1}
\maketitlesupplementary



\begin{lemma}[\textbf{Minimum of rotation residual}]\label{lemma:ls-rot}
	The minimum for all $\va, \vb \in \Rthree$
	\begin{equation}
		\begin{aligned}
			&\min_{\MR \in \SOthree} \normsq{\MR \va - \vb}\\
			&= \left( \norm{\va} - \norm{\vb} \right)^2
		\end{aligned}
	\end{equation}
\end{lemma}

\begin{proof}
\begin{equation}
	\begin{aligned}
		&\min_{\MR \in \SOthree} \normsq{\MR \va - \vb}\\
		=&\min_{\MR \in \SOthree} \left( \MR \va - \vb \right)^\transposed \left( \MR \va - \vb \right)\\
		=&\min_{\MR \in \SOthree} (\MR\va)^\transposed \MR\va - 2 (\MR \va)^\transposed \vb + \vb^\transposed \vb\\
		=&\min_{\MR \in \SOthree} \va^\transposed \MR^\transposed \MR \va - 2 (\MR \va)^\transposed \vb + \vb^\transposed \vb\\
		=&\min_{\MR \in \SOthree} \va^\transposed \va - 2 (\MR \va)^\transposed \vb + \vb^\transposed \vb\\
		=&\min_{\MR \in \SOthree} \normsq{\va} - 2 (\MR \va)^\transposed \vb  + \normsq{\vb}\\
		=& \normsq{\va} - 2 \norm{\va} \norm{\vb}  + \normsq{\vb}\\
		=& \left( \norm{\va} - \norm{\vb} \right)^2
	\end{aligned}
\end{equation}
	
\end{proof}



\section{Interval analysis of residuals under translation}
\label{proof:tls-relax-minmax-r}

\begin{theorem}
	The residual term $r_i = ||\mathbf{a}_i - \mathbf{b}_i + \mathbf{t}||_2^2$
	has the minimum $r_{min}^i = \max(0, ||\mathbf{d}||_2 - n_r)^2$ and the maximum $r_{max}^i = (||\mathbf{d}||_2 + n_r)^2$
	for any translation $\mathbf{t} \in \Rthree$ and $||\mathbf{c} - \mathbf{t}|| \leq n_r$ where $\mathbf{d} = \mathbf{a}_i - \mathbf{b}_i + \mathbf{c}$.
\end{theorem}

\begin{proof}
	With $\mathbf{t}= \mathbf{c} - \Delta \mathbf{t} \iff \Delta \mathbf{t} = \mathbf{c} - \mathbf{t}$:
	\begin{equation}
		\begin{aligned}
			r_i &= ||\mathbf{a}_i - \mathbf{b}_i + \mathbf{t}||_2^2
			= ||\mathbf{a}_i - \mathbf{b}_i + \mathbf{c} - \Delta\mathbf{t}||_2^2
			= ||\mathbf{d} - \Delta\mathbf{t}||_2^2\\ 
			&= (\mathbf{d} - \Delta\mathbf{t})^\transposed(\mathbf{d} - \Delta\mathbf{t})=
			\mathbf{d}^\transposed\mathbf{d} - 2 \mathbf{d}^\transposed \Delta\mathbf{t} + \Delta\mathbf{t}^\transposed \Delta\mathbf{t}\\
			&= ||\mathbf{d}||_2^2 - 2 \, ||\mathbf{d}|| \, ||\Delta\mathbf{t}||  \cos \theta + ||\Delta\mathbf{t}||_2^2\\
		\end{aligned}
	\end{equation}
	
	\begin{equation}
		\begin{aligned}
			r_{min}^i = \min_{\Delta \mathbf{t}} r_i &= 
			||\mathbf{d}||_2^2 + 
			\min_{\theta \in [-\pi, \pi], ||\Delta\mathbf{t}|| \in [0, n_r]} \left( -2 \, ||\mathbf{d}||  \, ||\Delta\mathbf{t}|| \cos \theta + ||\Delta\mathbf{t}||_2^2 \right) \\
			&= ||\mathbf{d}||_2^2 + \min_{||\Delta\mathbf{t}|| \in [0, n_r]} \left( -2 \, ||\mathbf{d}||  \, ||\Delta\mathbf{t}|| + ||\Delta\mathbf{t}||_2^2 \right) \\
			&= \min_{||\Delta\mathbf{t}|| \in [0, n_r]}  (||\mathbf{d}||_2 - ||\Delta\mathbf{t}||_2)^2\\
			&=\max(0, ||\mathbf{d}||_2 - n_r)^2\\
			r_{min}^i = \max_{\Delta \mathbf{t}} r_i &= 
			||\mathbf{d}||_2^2 + 
			\max_{\theta \in [-\pi, \pi], ||\Delta\mathbf{t}|| \in [0, n_r]} \left( -2 \, ||\mathbf{d}||  \, ||\Delta\mathbf{t}|| \cos \theta + ||\Delta\mathbf{t}||_2^2 \right) \\
			&= ||\mathbf{d}||_2^2 + 2 \, ||\mathbf{d}||\, n_r + n_r^2 = (||\mathbf{d}||_2 + n_r)^2
		\end{aligned}
	\end{equation}
	
\end{proof}

\section{Interval analysis of residuals under rotation}
\label{proof:wls-interval-analysis-rotation}

\begin{theorem}
	
	The residual term $r_i = ||\mathbf{a}_i - \mathbf{R}\mathbf{b}_i ||_2^2$
	has the minimum $r_{min}^i$ and the maximum $r_{max}^i$
	over all 3D-rotations $\mathbf{R} \in \SOthree$ that satisfy $d_{\angle}(\mathbf{R}, \mathbf{R_c}) \leq n_r$ where $\mathbf{R_c} \in \SOthree$ is the ball center:
	\begin{equation}
		\begin{aligned}
			r_{min}^i &= ||\mathbf{a}_i||^2 + ||\mathbf{b}_i||^2 - 2 ||\mathbf{a}_i|| \, ||\mathbf{b}_i|| \cos (\max(\theta - n_r, 0))\\
			r_{max}^i &= ||\mathbf{a}_i||^2 + ||\mathbf{b}_i||^2 - 2 ||\mathbf{a}_i|| \, ||\mathbf{b}_i|| \cos (\min(\theta + n_r, \pi))
		\end{aligned}
	\end{equation}
	with 
	\begin{equation}
		\begin{aligned}
			\theta &= \arccos \left( \frac{(\mathbf{R}_c^\transposed \, \mathbf{a}_i )^\transposed \mathbf{b}_i}
			{||\mathbf{a}_i|| \, || \mathbf{b}_i||} \right)
		\end{aligned}
	\end{equation}
	being the angle between $\mathbf{R}_c^\transposed \, \mathbf{a}_i $ and $\mathbf{b}_i$.
	
\end{theorem} 

\begin{proof}
	With $\mathbf{R}  = \mathbf{R}_c \Delta\mathbf{R} \iff \mathbf{R}_c^\transposed\mathbf{R} = \Delta \mathbf{R}$:
	\begin{equation}
		\begin{aligned}
			r_i &= ||\mathbf{a}_i - \mathbf{R}\mathbf{b}_i ||_2^2 \\
			&= || \mathbf{R}_c^\transposed \left(\mathbf{a}_i - \mathbf{R}\mathbf{b}_i\right) ||_2^2\\
			&= || \mathbf{R}_c^\transposed \mathbf{a}_i - \mathbf{R}_c^\transposed \mathbf{R}\mathbf{b}_i ||_2^2\\
			&= \left(\mathbf{R}_c^\transposed \mathbf{a}_i - \Delta \mathbf{R}\mathbf{b}_i \right)^\transposed
			\left(\mathbf{R}_c^\transposed \mathbf{a}_i - \Delta \mathbf{R}\mathbf{b}_i \right)\\ 
			&= \left(\mathbf{R}_c^\transposed \mathbf{a}_i \right)^\transposed \left(\mathbf{R}_c^\transposed \mathbf{a}_i \right) - 2 (\mathbf{R}_c^\transposed\mathbf{a}_i )^\transposed \Delta\mathbf{R}\mathbf{b}_i + (\Delta \mathbf{R}\mathbf{b}_i )^\transposed (\Delta \mathbf{R}\mathbf{b}_i )\\
			&= \mathbf{a}_i^\transposed \mathbf{R}_c \mathbf{R}_c^\transposed \mathbf{a}_i - 2 (\mathbf{R}_c^\transposed\mathbf{a}_i )^\transposed \Delta\mathbf{R}\mathbf{b}_i + \mathbf{b}_i^\transposed  \Delta \mathbf{R}^\transposed  \Delta \mathbf{R}\mathbf{b}_i\\
			&= \mathbf{a}_i^\transposed \mathbf{a}_i - 2 (\mathbf{R}_c^\transposed\mathbf{a}_i )^\transposed \Delta\mathbf{R}\mathbf{b}_i + \mathbf{b}_i^\transposed \mathbf{b}_i\\
			&= ||\mathbf{a}_i||^2 + ||\mathbf{b}_i||^2 - 2 (\mathbf{R}_c^\transposed\mathbf{a}_i )^\transposed \Delta\mathbf{R}\mathbf{b}_i
		\end{aligned}
	\end{equation}
	Since $\Delta \mathbf{R}$ is defined as rotating a point by at most $n_r$ (definition of geodesic distance $d_{\angle}(\mathbf{R}, \mathbf{R_c}) \leq n_r \iff d_{\angle}(\mathbf{I}, \Delta \mathbf{R} \leq n_r$) from this follows:
	\begin{equation}
		\begin{aligned}
			r_{min}^i &= \min_{\Delta \mathbf{R} \in \SOthree, \, d_{\angle}(\mathbf{I}, \Delta \mathbf{R}) \leq n_r} \left( ||\mathbf{a}_i||^2 + ||\mathbf{b}_i||^2 - 2 (\mathbf{R}_c^\transposed\mathbf{a}_i )^\transposed \Delta\mathbf{R}\mathbf{b}_i \right)\\ 
			&= ||\mathbf{a}_i||^2 + ||\mathbf{b}_i||^2 - 2 ||\mathbf{a}_i|| \, ||\mathbf{b}_i|| \cos (\max(\theta - n_r, 0)) \\
			r_{max}^i &=
			\max_{\Delta \mathbf{R} \in \SOthree, \, d_{\angle}(\mathbf{I}, \Delta \mathbf{R}) \leq n_r} \left( ||\mathbf{a}_i||^2 + ||\mathbf{b}_i||^2 - 2 (\mathbf{R}_c^\transposed\mathbf{a}_i )^\transposed \Delta\mathbf{R}\mathbf{b}_i \right)\\ 
			&=  ||\mathbf{a}_i||^2 + ||\mathbf{b}_i||^2 - 2 ||\mathbf{a}_i|| \, ||\mathbf{b}_i|| \cos (\min(\theta + n_r, \pi))
		\end{aligned}
	\end{equation}
	
\end{proof}

\begin{theorem}
	
	For the truncated least-squares function:
	
	\begin{equation}
		\label{eq:tls-t-opt-branch2}
		\begin{aligned}
			\text{TLS}(\mathbf{x}) = \sum_{i=1}^{N} \min \left(r(\mathbf{x}, \mathbf{x}_i)^2, \epsilon^2 \right)\\
		\end{aligned}
	\end{equation}
	
	where $\mathbf{x}_i$ are data points and $r(\mathbf{x}, \mathbf{x}_i)^2 = r_i$ are residual terms convex in $\mathbf{x}$. Given are the minimum and maximum value of each residual term $r_i$ over every $\mathbf{x} \in \mathcal{X}$, denoted as $r_{min}^i$ and $r_{max}^i$ respectively. Then, $\text{WLS}_{r}$ is a convex relaxation of \ref{eq:tls-t-opt-branch2} over $\mathcal{X}$:
	\begin{equation}
		\label{eq:tls-wls-relaxation}
		\begin{aligned}	
			\text{WLS}_{r}(\mathbf{x}) &= 
			\sum_{i=1}^{N} (1 - o_i) \left(w_i r_i  + (1 - w_i) r_{min}^i \right) + \sum_{i=1}^{N} o_i\epsilon^2\\
		\end{aligned}
	\end{equation}
	
	with the weights $w_i$ defined as:
	\begin{equation}
		\begin{aligned}	
			w_i  = 
			\begin{cases}
				\frac{\epsilon^2 - r_{min}^i}{r_{max}^i - r_{min}^i} &  r_{max}^i > \epsilon^2\\
				1 & \, \text{otherwise}
			\end{cases}
		\end{aligned}
	\end{equation}
	
	and the binary variables $o_i$ deciding whether the $i$-th residual is an outlier or not:
	\begin{equation}
		\begin{aligned}	
			o_i &= \begin{cases}
				1 &  r_{min}^i > \epsilon^2\\
				0 & \, \text{otherwise}
			\end{cases}
		\end{aligned}
	\end{equation}
	
\end{theorem}	

\begin{proof}
	
	In the truncated-least-squares function, non-convexity is introduced solely by the truncation since the squared terms are convex.
	Therefore, we only need to show that the re-weighted sum leads to the residuals not being truncated. 
	For this, we apply an affine transform on each residual so that $w_i r_i + y_0 = r_{min}^i$ for $r_i = r_{min}^i$ and $w_i r_i + y_0 = \epsilon^2$ for $r_i = r_{max}^i$:
	Subtracting the first from the second equation yields:
	\begin{equation}
		\begin{aligned}	
			&w_i (r_{max}^i - r_{min}^i) = \epsilon^2 - r_{min}^i\\
			\iff &w_i  = \frac{\epsilon^2 - r_{min}^i}{r_{max}^i - r_{min}^i}
		\end{aligned}
	\end{equation}
	and solving for $y_0$ yields:
	\begin{equation}
		\begin{aligned}	
			w_i r_{min}^i + y_0 &= r_{min}^i\\
			\iff y_0 &= r_{min}^i - w_i r_{min}^i\\
			\iff y_0 &= (1- w_i) r_{min}^i
		\end{aligned}
	\end{equation}
	
	Therefore, $w_k r_k + (1 - w_k) r_{min}^k \leq \epsilon^2$ holds for all $k$ for which $o_k = 0$ and therefore these terms are not truncated and thus convex. The sum
	
	\begin{equation}
		\begin{aligned}	
			\sum_{i=1}^{N} (1 - o_i) \left(w_i r_i  + (1 - w_i) r_{min}^i \right)
		\end{aligned}
	\end{equation}
	
	is therefore convex since sums of convex functions are convex \cite[Ch. 2.3.2, p.36]{Boyd_Vandenberghe_2004}.
	
	Since $\sum_{i=1}^{N} o_i\epsilon^2$ is constant, the overall term \ref{eq:tls-wls-relaxation} also remains convex. Since $r_k \in [r^k_{min}, r^k_{max}]$ and $w_k \leq 1$, $w_k r_k  + (1 - w_k) r_{min}^k \leq r_k$ for all $k$ for which $o_k = 0$  Eq. \ref{eq:tls-wls-relaxation} is below the objective \ref{eq:tls-t-opt-branch2}. Therefore, \ref{eq:tls-wls-relaxation} is a convex relaxation of \ref{eq:tls-t-opt-branch2} over $\mathcal{X}$.
	
\end{proof}	

\section{Least-squares rotation estimation with equality-constrained angle}
\label{proof:wls-relax-eq-constrained-rotation}

\begin{theorem}
	\label{thm:constrained-wahba-davenport}
	The least-squares rotation estimation problem 
	\begin{equation}
		\label{eq:tls-rwls-a}
		\begin{aligned}
			\argmin_{\mathbf{R} \in \SOthree}  \quad &\sum_{i=1}^{N} w_i ||\mathbf{R}_c^\transposed \mathbf{a}_i - \Delta\mathbf{R} \mathbf{b}_i ||_2^2 \\
			\text{subject to} \quad &d_{\angle}(\mathbf{I}, \Delta\mathbf{R}) = n_r
		\end{aligned}
	\end{equation}
	where the angle of rotation is constrained equal to $n_r$ is equivalent to the following optimization problem over the rotation axis $\mathbf{n}$:
	\begin{equation}
		\label{eq:rot-est-constrained-qcqp}
		\begin{aligned}
			\argmin_{\mathbf{n} \in \Rthree} \quad &-\left(\mathbf{n}^\transposed \mathbf{A} \mathbf{n} + 2 \mathbf{g}^\transposed \mathbf{n} \right)\\
			\text{subject to} \quad &|| \mathbf{n}|| = 1\\
		\end{aligned}
	\end{equation}
	with
	\begin{equation}
		\label{eq:ev-constr-data-mat-a}
		\begin{aligned}
			\mathbf{A} &= \sin^2 \left(\frac{n_r}{2} \right) \mathbf{C}, \quad \mathbf{g} =  \sin \left(\frac{n_r}{2} \right) \cos \left(\frac{n_r}{2} \right) \mathbf{z}\\
			\mathbf{C} &= \mathbf{B} + \mathbf{B}^\transposed\\
			\mathbf{B} &= \sum_{i=1}^N w_i \mathbf{a}_i\mathbf{b}_i^\transposed \in \Rone^{3 \times 3}, \quad
			\mathbf{z} = \sum_{i=1}^N w_i [\mathbf{a}_i]_{\times}\mathbf{b}_i \in \Rone^{3}
		\end{aligned}
	\end{equation}
\end{theorem}

\begin{proof}
	
	The problem \ref{eq:tls-rwls-a} without the equality constraint (i.e. the Wahba problem) can be stated equivalently using quaternions as:
	\begin{equation}
		\label{eq:davenports-q-problem}
		\begin{aligned}
			\max_{\mathbf{q} \in \Rone^4} &\quad \mathbf{q}^\transposed \mathbf{K} \mathbf{q}\\
			\text{subject to} &\quad  ||\mathbf{q}|| = 1
		\end{aligned}
	\end{equation}
	where $\mathbf{q}$ is the quaternion and $\mathbf{K} \in \Rone^{4\times4}$ is a data matrix.
	The data matrix $\mathbf{K}$ has the following block-structure:
	
	\begin{equation}
		\label{eq:k-mat}
		\begin{aligned}
			\mathbf{K} = \left(
			\begin{array}{c|c}
				\begin{array}{ccc}
					& & \\
					& \mathbf{C} & \\
					& & 
				\end{array}
				&
				\begin{array}{c}
					\mathbf{z} \\
				\end{array}
				\\
				\hline
				\begin{array}{ccc}
					& \mathbf{z}^\transposed &
				\end{array}
				&
				\trace(\mathbf{C})
			\end{array}
			\right) \in \Rone^{4 \times 4}
		\end{aligned}
	\end{equation}
	
	where the matrices $\mathbf{C}$ and $\mathbf{z}$ are defined as in the theorem \ref{eq:ev-constr-data-mat-a}. 
	We can separate now the optimization over the rotation axis and angle using the following definition:
	
	\begin{equation}
		\label{eq:q-axis-angle}
		\begin{aligned}
			\mathbf{q} = \left( \sin \left( \frac{\theta}{2} \right) \mathbf{n}, \cos \left(\frac{\theta}{2} \right) \right)^\transposed
		\end{aligned}
	\end{equation}
	where $\mathbf{n} \in \Rthree$ is a unit-vector that is the axis of rotation and $\theta$ is the angle of rotation.
	We rewrite the objective function $\mathbf{q}^\transposed \mathbf{K} \mathbf{q}$  of \ref{eq:davenports-q-problem} using the blocks of the block-matrix $\mathbf{K}$: 
	
	\begin{equation}
		\label{eq:dv-q-rew}
		\begin{aligned}
			&\mathbf{q}^\transposed \mathbf{K} \mathbf{q}\\
			&= \sin^2 \left(\frac{\theta}{2} \right) \mathbf{n}^\transposed \mathbf{C} \mathbf{n} + 2 \sin \left(\frac{\theta}{2} \right) \cos \left(\frac{\theta}{2} \right) \mathbf{z}^\transposed \mathbf{n} + \cos^2 \left(\frac{\theta}{2} \right) \trace(\mathbf{C})
		\end{aligned}
	\end{equation}
	
	Now the axis $\mathbf{n}$ and the angle $\theta$ occur separately. 
	By the equality constraint, $\theta$ is already given as $\theta = n_r$. Then, the term $ \cos^2 \left(\frac{\theta}{2} \right) \trace(\mathbf{C})$ in Eq. \ref{eq:dv-q-rew} is constant and does not affect the minimizer, we will therefore omit it. 
	 By defining the data-matrices $\mathbf{A}$ and $\mathbf{g}$ as in the theorem \ref{eq:ev-constr-data-mat-a}, we see that the objective function of Eq. \ref{eq:rot-est-constrained-qcqp} is equivalent to Davenports' problem \ref{eq:davenports-q-problem} and therefore equivalent to \ref{eq:tls-rwls-a}, concluding the proof.
\end{proof}	


\begin{proof}
	We first form the Lagrangian to account for the constraint:
	\begin{equation}
		\begin{aligned}	
			L(\mathbf{x}, \lambda) =  \sum_{i=1}^{N} w_i ||\mathbf{d}_i - \mathbf{x}||_2^2 + \lambda (
			\mathbf{x}^\transposed \mathbf{x} - n_r^2)\\
		\end{aligned}
	\end{equation}
	
	then, we set the first partial derivatives to zero: 
	\begin{equation}
		\begin{aligned}	
			\frac{\partial L}{\partial \mathbf{x}} &= \frac{\partial }{\partial \mathbf{x}} \left( \sum_{i=1}^{N} w_i \left(\mathbf{d}_i - \mathbf{x}\right)^\transposed \left(\mathbf{d}_i - \mathbf{x}\right) + \lambda (
			\mathbf{x}^\transposed \mathbf{x} - n_r^2) \right)\\
			&= - 2\sum_{i=1}^{N} w_i \left(\mathbf{d}_i - \mathbf{x}\right) + 2 \lambda \mathbf{x}\\
			&= \mathbf{0}\\
		\end{aligned}
	\end{equation}
	
	
	By rearranging, we can obtain therefore the solution in closed form:
	\begin{equation}
		\label{eq:trans-qcqp-lagrangian}
		\begin{aligned}	
			-2  &\sum_{i=1}^{N}  w_i \left(\mathbf{d}_i - \mathbf{x}\right) + 2 \lambda \mathbf{x} = \mathbf{0}\\
			\iff \lambda \mathbf{x} &= \sum_{i=1}^{N} w_i \left(\mathbf{d}_i - \mathbf{x}\right)\\
			\lambda \mathbf{x} &= \sum_{i=1}^{N}  w_i \mathbf{d}_i  - \sum_{i=1}^{N}  w_i \mathbf{x}\\
			\lambda \mathbf{x} &= \sum_{i=1}^{N}  w_i \mathbf{d}_i  - \mathbf{x} \sum_{i=1}^{N}  w_i\\
			\left( \lambda + \sum_{i=1}^{N}  w_i \right) \mathbf{x} &= \sum_{i=1}^{N} w_i \mathbf{d}_i \\
			\mathbf{x} &= \frac{1}{\lambda + \sum_{i=1}^{N}  w_i} \sum_{i=1}^{N} w_i \mathbf{d}_i 
		\end{aligned}
	\end{equation}
	
	Now the Karush-Kuhn-Tucker (KKT) conditions require $\lambda \geq 0$ and $\lambda (
	\mathbf{x}^\transposed \mathbf{x} - n_r^2) = 0$ in addition to satisfying the constraint, i.e. $|| \mathbf{x}||_2 \leq n_r$.
\end{proof}
	
