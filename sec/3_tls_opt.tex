
\section{Problem formulation}
The problem is to compute a 3D-transform $(\MR^*, \vt^*) \in \SEthree$ that optimally aligns two point sequences $\mathcal{P} = \left(\vp_1, ..., \vp_N\right), \mathcal{Q} = \left(\vq_1, ..., \vq_N\right) \in \RthreeByN$ of noisy measurements. We know the correspondences between points ($\vp_i$ and $\vq_i$), but a large fraction (up to 95\%) can be outliers, as it is typical for feature-based matching methods.
\subsection{The Truncated Least Squares problem}
\begin{figure}[!ht]
	\centering
	\begin{adjustbox}{width=1.\linewidth}
		\input{figures/tls_cost_many_term.pgf}
	\end{adjustbox}
	\caption{The non-convex Truncated least-squares (TLS) function with multiple local minima.Shown is the function  $\sum_{i=1}^{N}\min((x - y_i)^2, \epsilon^2)$ for $\epsilon^2=0.1$, and nine $y_i$'s (gray lines).}
	\label{fig:tlscostmulterm}
\end{figure}

The Truncated Least Squares (TLS) problem is a least squares estimation problem where residuals are truncated above a threshold. (It is similar to the Maximum Consensus problem but additionally considers the residual values, obtaining slightly better estimates.)
Outliers are handled by truncating residuals above a threshold $\epsilon^2$, the objective function is therefore:


\begin{equation}
	\begin{aligned}
		\text{TLS}(x) = \sum_{i=1}^{N}\min(r(x, y_i)^2, \epsilon^2)
	\end{aligned}
\end{equation}

where $r(\cdot)$ is a residual function like $\norm{x - \vy_i}$ measuring the deviation of the model given the parameters $x$ and the data points $\vy_i$. This function is shown in Fig. \ref{fig:tlscostmulterm}.

The point cloud registration problem in the TLS formulation is therefore:

\begin{equation}
	\label{eq:pcr-tls}
	\begin{aligned}
		(\MR^*, \vt^*) =  \argmin_{(\MR, \vt) \in \SEthree}  \sum_{i=1}^{N} \min \left(\normsq{\MR \vp_i  - \vq_i  + \vt}, \epsilon^2 \right)
	\end{aligned}
\end{equation}

Among the many ways to make least squares regression robust to outliers \cite[Ch. 3]{elements-of-stats-learning-book}, the TLS formulation has recently gained populariy \cite{Yang20tro-teaser, 9785843, NIPS2017_9f53d83e, doi:10.1080/10618600.2017.1390471, NIPS2010_01882513} since it has been shown to be very robust even to high outlier rates of 90\% \cite{Yang20tro-teaser}.
This problem is a non-convex combinatorial problem that is difficult to solve (requiring non-convex binary constraints \cite{5459398}).

The parameter $\epsilon$ is best understood as the known measurement accuracy of each point. It can be estimated by collecting samples, i.e. in a data-driven manner \cite[p.8]{Chin2017TheMC}.


\section{Wheighted Least Squares convex relaxation}

In this section we propose a novel convex relaxation for the Truncated Least Squares problem that can be computed in linear time.

\begin{figure}[!ht]
	\centering
	\caption{The idea of the WLS convex relaxation: We compute the maximum $r_{max}$ of each convex term (orange) over the given interval (blue) and then re-weight it such that it remains below $\epsilon^2$ over this interval and is thus not truncated over the entire interval (green).}
	\label{fig:wlsrelaxideawithrelax}
\end{figure}

First, consider the truncated least squares objective for a general residual term $r(\cdot)$ that depends on the model (i.e rotation or translation): 

\begin{equation}
	\label{eq:tls-scalar-for-wls}
	\begin{aligned}
		\text{TLS}(\mathbf{x}) = \sum_{i=1}^{N} \min \left(r(\mathbf{x}, \mathbf{x}_i)^2, \epsilon^2 \right)\\
	\end{aligned}
\end{equation}

where $\mathbf{x}_i$ are data points and $r(\cdot)^2$ is some convex residual function such as the squared Euclidean distance $||\mathbf{x} - \mathbf{x}_i||_2^2$. In the following, we will refer to the i-th residual term $r(\mathbf{x}, \mathbf{x_i})^2$ simply as $r_i$.
The idea of the WLS-relaxation is the observation that this function is only non-convex because of the truncation -- the residuals are convex (parabolas). Since sums of convex functions are convex, we can focus on relaxing each term separately.

For this, we first find the minimum and maximum values of each residual $r_i$ is over the given interval, denoted as $r_{min}^i$ and $r_{max}^i$ respectively. The key geometric idea of our relaxation is to reweight these residuals such that after reweighting, their maximum becomes $\epsilon^2$ and thus they are not affected by truncation (Fig. \ref{fig:wlsrelaxideawithrelax}).

Some additional case handling is required however to ensure that this relaxation becomes tight. This is crucial to ensure that BnB converges in a finite number of iterations. First, all residuals for which  $r_{min} \geq \epsilon^2$ holds are outliers over the entire interval and therefore constant. Similarly, residuals where $r_{max} \leq \epsilon^2$ holds are inliers over the entire interval and do not need to be reweighted.

After considering these special cases, we can show that $\text{WLS}_{relax}$ is a convex relaxation of \ref{eq:tls-scalar-for-wls} over a given interval:
\begin{equation}
	\label{eq:tls-wls-relaxation1}
	\begin{aligned}	
		\text{WLS}_{relax} &= 
		\sum_{i=1}^{N} (1 - o_i) \left(w_i r_i  + (1 - w_i) r_{min}^i \right) + \sum_{i=1}^{N} o_i\epsilon^2\\
	\end{aligned}
\end{equation}

with the weights $w_i$ defined as:
\begin{equation}
	\begin{aligned}	
		w_i  = 
		\begin{cases}
			\frac{\epsilon^2 - r_{min}^i}{r_{max}^i - r_{min}^i} &  r_{max}^i > \epsilon^2\\
			1 & \, \text{otherwise}
		\end{cases}
	\end{aligned}
\end{equation}

and the binary variables $o_i$ deciding whether the $i$-th residual is an outlier or not:
\begin{equation}
	\begin{aligned}	
		o_i &= \begin{cases}
			1 &  r_{min}^i > \epsilon^2\\
			0 & \, \text{otherwise}
		\end{cases}
	\end{aligned}
\end{equation}

For a proof of this WLS-relaxation, see \ref{proof:tls-convex-wls-relaxation}.

\subsection{Interval analysis of residuals}

In the following we show how $r_{min}$ and $r_{max}$ can easily be computed analytically for different models (i.e. translation and rotation), given spherical intervals, i.e. balls.

\subsubsection{Translation}
The minimum $r_{min}^i$ and maximum $r_{max}^i$ of the residual $r_i =||\mathbf{a}_i - \mathbf{b}_i + \mathbf{t}||_2^2$ (translation) over a ball with center $\mathbf{c}$ and radius $n_r$ are: (see \ref{proof:tls-relax-minmax-r} for a proof):

\begin{equation}
	\begin{aligned}	
		r_{min}^i &= \max(0, ||\mathbf{d}_i||_2 - n_r)^2\\
		r_{max}^i &= (||\mathbf{d}_i||_2 + n_r)^2
	\end{aligned}
\end{equation}

with $\mathbf{d}_i$ defined as: 

\begin{equation}
	\begin{aligned}	
		\mathbf{d}_i = \mathbf{a}_i - \mathbf{b}_i + \mathbf{c}
	\end{aligned}
\end{equation}

\subsubsection{Rotation}

Similarly, for the rotation residual $||\mathbf{a}_i - \mathbf{R}\mathbf{b}_i ||_2^2$ over a over a ball with center $\mathbf{R}_c$ and (geodesic) radius $n_r$ they are (see \ref{proof:wls-interval-analysis-rotation} for a proof): 

\begin{equation}
	\label{eq:residual-minmax-rotation}
	\begin{aligned}
		r_{min}^i = ||\mathbf{a}_i||^2 + ||\mathbf{b}_i||^2 - 2 ||\mathbf{a}_i|| \, ||\mathbf{b}_i|| \cos (\max(\theta - n_r, 0))\\
		r_{max}^i = ||\mathbf{a}_i||^2 + ||\mathbf{b}_i||^2 - 2 ||\mathbf{a}_i|| \, ||\mathbf{b}_i|| \cos (\min(\theta + n_r, \pi))
	\end{aligned}
\end{equation}

where $\theta$ is the angle between $\mathbf{R}_c^\transposed \,\mathbf{a}_i$ and $\mathbf{b}_i$:

\begin{equation}
	\begin{aligned}
		\theta = \arccos \left( \frac{(\mathbf{R}_c^\transposed \, \mathbf{a}_i )^\transposed \mathbf{b}_i}{|| \mathbf{a}_i || \, || \mathbf{b}_i ||} \right)
	\end{aligned}
\end{equation}

Computing these intervals requires constant time and is in practice very fast when using trigonometric identities to elimitade the the need for evaluating the cosine function.

\subsubsection{Rotation and Translation (3D-transform)}

To solve the full 6DoF problem, we will need the residual interval over a translation ball and \textit{any} rotation, later it  will become aparent why no rotation ball is needed.

The minimum over all translations $\vt \in B^t(\vc) := \{\vt \in \Rthree: \norm{\vc - \vt}_2 \leq n_r\}$ for all $\vp, \vq \in \Rthree$ is
\begin{equation}
	\begin{aligned}
		&\min_{\MR \in \SOthree, \vt \in B^t(\vc)} \normsq{\MR \vp - \vq + \vt}\\
		&= \max \left(  0, | \norm{\vp} - \norm{\vq + \vc} | - n_r \right)^2
	\end{aligned}
\end{equation}

\section{Minimizing the WLS convex relaxation}
After having computed the WLS relaxation (i.e. the weights), we need to minimize it to obtain a lower bound on the TLS objective. 
Since the relaxation is a simple weighted least squares function, minimizing it is rather easy. The only thing we need to consider is that we seek the minimum that is inside the Branch and Bound node. We therefore need to introduce an inequality constraint into the minimization problem.
This constrained problem still can be solved very efficiently by utilizing custom active-set solvers, they are only slightly more expensive than solving the least-squares problem.

\subsection{Minimizing the WLS-relaxation over translations}

The problem of minimizing the WLS-relaxation over a ball $\{ \mathbf{t} \in \Rthree : || \mathbf{c} - \mathbf{t} || \leq n_r \}$ of translations is:
\begin{equation}
	\label{eq:tls-twls-constrained}
	\begin{aligned}
		\argmin_{\mathbf{t} \in \Rone^3} \quad &\sum_{i=1}^{N} w_i ||\mathbf{a}_i - \mathbf{b}_i + \mathbf{c} - \mathbf{t}||_2^2 \\
		\text{subject to} \quad  &||\mathbf{c} - \mathbf{t}||_2 \leq n_r
	\end{aligned}
\end{equation}

The ball center $\mathbf{c}$ is the center of the BnB node that has a radius $n_r$. 
The constraint $||\mathbf{c} - \mathbf{t}||_2 \leq n_r$ therefore ensures  that the found $\mathbf{t}$ is inside the BnB node. Note that compared to the definition of the convex relaxation \ref{eq:tls-wls-relaxation1}, two constant sums disappeared because they are constant (i.e. they do not depend on $\mathbf{t}$). 
We can write this problem equivalently as:
\begin{equation}
	\label{eq:tls-twls-constrained}
	\begin{aligned}
		\argmin_{\mathbf{x} \in \Rone^3} \quad &\sum_{i=1}^{N} w_i ||\mathbf{d}_i - \mathbf{x}||_2^2 \\
		\text{subject to} \quad  &||\mathbf{x}||_2 \leq n_r
	\end{aligned}
\end{equation}
with 
\begin{equation}
	\begin{aligned}
		\mathbf{x} = \mathbf{c} - \mathbf{t}, \quad \mathbf{d}_i = \mathbf{a}_i - \mathbf{b}_i + \mathbf{c}
	\end{aligned}
\end{equation}

This problem can be solved easily in closed form.
We first form the Lagrangian to account for the constraint:
\begin{equation}
	\begin{aligned}	
		L(\mathbf{x}, \lambda) =  \sum_{i=1}^{N} w_i ||\mathbf{d}_i - \mathbf{x}||_2^2 + \lambda (
		\mathbf{x}^\transposed \mathbf{x} - n_r^2)\\
	\end{aligned}
\end{equation}

then, we set the first partial derivatives to zero: 
\begin{equation}
	\begin{aligned}	
		\frac{\partial L}{\partial \mathbf{x}} &= \frac{\partial }{\partial \mathbf{x}} \left( \sum_{i=1}^{N} w_i \left(\mathbf{d}_i - \mathbf{x}\right)^\transposed \left(\mathbf{d}_i - \mathbf{x}\right) + \lambda (
		\mathbf{x}^\transposed \mathbf{x} - n_r^2) \right)\\
		&= - 2\sum_{i=1}^{N} w_i \left(\mathbf{d}_i - \mathbf{x}\right) + 2 \lambda \mathbf{x}\\
		&= \mathbf{0}\\
	\end{aligned}
\end{equation}


By rearranging, we can obtain therefore the solution in closed form:
\begin{equation}
	\label{eq:trans-qcqp-lagrangian}
	\begin{aligned}	
		-2  &\sum_{i=1}^{N}  w_i \left(\mathbf{d}_i - \mathbf{x}\right) + 2 \lambda \mathbf{x} = \mathbf{0}\\
		\iff \lambda \mathbf{x} &= \sum_{i=1}^{N} w_i \left(\mathbf{d}_i - \mathbf{x}\right)\\
		\lambda \mathbf{x} &= \sum_{i=1}^{N}  w_i \mathbf{d}_i  - \sum_{i=1}^{N}  w_i \mathbf{x}\\
		\lambda \mathbf{x} &= \sum_{i=1}^{N}  w_i \mathbf{d}_i  - \mathbf{x} \sum_{i=1}^{N}  w_i\\
		\left( \lambda + \sum_{i=1}^{N}  w_i \right) \mathbf{x} &= \sum_{i=1}^{N} w_i \mathbf{d}_i \\
		\mathbf{x} &= \frac{1}{\lambda + \sum_{i=1}^{N}  w_i} \sum_{i=1}^{N} w_i \mathbf{d}_i 
	\end{aligned}
\end{equation}

Now the Karush-Kuhn-Tucker (KKT) condition of complementary slackness requires $\lambda \geq 0$ and $\lambda (
\mathbf{x}^\transposed \mathbf{x} - n_r^2) = 0$ in addition to satisfying the constraint, i.e. $|| \mathbf{x}||_2 \leq n_r$. It follows that we can obtain the optimum by first computing $\mathbf{x}$ with Eq. \ref{eq:trans-qcqp-lagrangian}, assuming $\lambda = 0$. Then we check whether the inequality constraint is satisfied, i.e. whether $|| \mathbf{x}||_2 \leq n_r$ holds, and if not, we simply normalize $\mathbf{x}$ so that it has the norm $n_r$. In other words, we see already from Eq. \ref{eq:trans-qcqp-lagrangian} that the Lagrange multiplier does not change the direction of $\mathbf{x}$, only its length.

This optimization problem is a special case of the Trust Region Problem for which strong duality holds \cite[Ch. 5.2, p.229]{Boyd_Vandenberghe_2004}.

\subsection{Minimizing the WLS-relaxation over rotations}

To problem of minimizing the WLS relaxation over a geodesic ball of rotations $\{\mathbf{R} \in \SOthree:  d_{\angle}(\mathbf{R}_c, \Delta\mathbf{R}) \leq n_r\}$ is:

\begin{equation}
	\label{eq:tls-rwls}
	\begin{aligned}
		\argmin_{\mathbf{R} \in \SOthree}  \quad &\sum_{i=1}^{N} w_i ||\mathbf{R}\mathbf{p}_i - \mathbf{q}_i ||_2^2 \\
		\text{subject to} \quad &d_{\angle}(\mathbf{R}_c, \Delta\mathbf{R}) \leq n_r
	\end{aligned}
\end{equation}

where $\mathbf{R_c}$ is the ball center and $n_r$ is the radius, as in the translation case. $d_{\angle}(\cdot)$ is the geodesic (also called angular) distance.
We can write this problem equivalently (due to the bi-invariance of the metric over $\SOthree$) as:
\begin{equation}
	\label{eq:tls-rwls}
	\begin{aligned}
		\argmin_{\Delta \mathbf{R} \in \SOthree}  \quad &\sum_{i=1}^{N} w_i ||\mathbf{R}_c^\transposed \mathbf{a}_i - \Delta\mathbf{R} \mathbf{b}_i ||_2^2 \\
		\text{subject to} \quad &d_{\angle}(\mathbf{I}, \Delta\mathbf{R}) \leq n_r
	\end{aligned}
\end{equation}


Where $\Delta\mathbf{R}$ is the rotation relative to the node's center and $\mathbf{I}$ is the identity rotation:  

\begin{equation}
	\begin{aligned}
		\Delta\mathbf{R} = \mathbf{R_c}^\transposed\mathbf{R} 
	\end{aligned}
\end{equation}

The unconstrained version of this problem is known as the \textit{Wahba-problem} for which a simple SVD-algorithm exists \cite{Kabsch-1978-Point-set-alignment} \cite{Lawrence2019APA} \cite{Least-squares-estimation-point-sets-Umeyama-1991}. Our problem however has additionally an inequality-constraint. It still can be solved computationally very efficient using a custom active-set solver.

The idea of the active set method is based on the observation that every inequality constraint can either be ignored or is satisfied as an equality (also called complementary slackness condition) \cite[Ch.15 p.424-427]{Numerical-Optimization-Nocedal-Wright}. We therefore first solve the problem using the SVD algorithm and thereby ignore the constraint. Then, we simply check whether the constraint is satisfied. If yes, we already have found the solution. If not, we know that we need to find a 3D rotation that has a rotation angle equal to $n_r$. By the Euler theorem, every 3D rotation can be described as a rotation around a single axis and an single angle. Because we know that the rotation angle needs to be $n_r$, we therefore only need to find the rotation axis.

Our active-set solver for finding the global minimum of the WLS-relaxation over rotations is is overall very efficient. The only computationally intensive operation is computing the $3 \times 3$ cross-correlation matrix that is needed first by the SVD algorithm. It has a linear runtime in the number of points. All the operations that follow are based on this $3 \times 3$ matrix and therefore have a constant runtime (i.e. independent of the number of points).
This solver is novel to our knowledge -- the problem of solving the Wahba-problem with inequality-constrained angle has not been proposed in the literature before.

\subsubsection{Solving the equality-constrained case}
In the equality-constrained case of the active-set solver, we need to find a 3D rotation with a rotation angle of exactly $n_r$:

\begin{equation}
	\label{eq:tls-rwls-eq}
	\begin{aligned}
		\argmin_{\Delta \mathbf{R} \in \SOthree}  \quad &\sum_{i=1}^{N} w_i ||\mathbf{R}_c^\transposed \mathbf{a}_i - \Delta\mathbf{R} \mathbf{b}_i ||_2^2 \\
		\text{subject to} \quad &d_{\angle}(\mathbf{I}, \Delta\mathbf{R}) = n_r
	\end{aligned}
\end{equation}

We show that this optimization problem is equivalent to the following problem over the axis of rotation:

\begin{equation}
	\begin{aligned}
		\label{eq:eq-constrained-prob-ev}
		\mathbf{n}^* = \argmin_{\mathbf{n} \in \Rthree} \quad &-\left(\mathbf{n}^\transposed \mathbf{A} \mathbf{n} + 2 \mathbf{g}^\transposed \mathbf{n} \right)\\
		\text{subject to} \quad &|| \mathbf{n}|| = 1\\
	\end{aligned}
\end{equation}

The data matrices $\mathbf{A}$ and $\mathbf{g}$ depend on the points $\mathbf{a}_i$ and $\mathbf{b}_i$ and the angle constraint $n_r$. A definition is given in the Appendix \ref{thm:constrained-wahba-davenport}.

To solve this non-convex optimization problem \ref{eq:eq-constrained-prob-ev} over the sphere, we use the algorithm proposed in \cite{10.1007/978-3-642-75536-1_57}. We perform overall two steps: We first compute the eigenvalue decomposition $\mathbf{A} = \mathbf{Q}\mathbf{\Lambda}\mathbf{Q}^\transposed$ and then find the rightmost root of a certain rational function (a characteristic polynomial). This can be done in practice very fast, yielding a constant time algorithm.
